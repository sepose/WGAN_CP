{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## WGAN CP (Wasserstein GAN)"
      ],
      "metadata": {
        "id": "fv4cR3_C-wCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "201912203 이승찬\n",
        "\n",
        "1.라이브러리 및 구글 드라이브 연결, 경로 설정"
      ],
      "metadata": {
        "id": "u2I19QlWAVMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  WGAN CP\n",
        "\n",
        "  - Wasserstein GAN 이며, 손실함수에 Wasserstein 거리를 이용하기 때문에 이렇게 불린다.\n",
        "  - Discriminator가 Critic으로 바뀌는데, Real과 Fake를 구분하기 보다는 점수를 매기는 역할을 하기 때문이다.\n",
        "  - Critic은 출력에 Sigmoid가 적용되어 있지 않아, 확률이 아닌 수를 출력하고 C_Real - C_Fake가 커지도록 강화된다.\n",
        "  - WGAN의 NetC에 클리핑이 적용되어 있다.\n",
        "  - 손실함수는 기존의 nn.BCE 에서 torch.mean(ouput)으로 바뀌었다.\n",
        "  - Optimizer는 Adam 대신 RMSProp를 사용하게 바뀌었다.\n",
        "  - 100 iter마다 진행상황을 출력하고, 1000 iter 마다영상을 저장한다.\n",
        "  - batch_size = 256, learning_rate = 0.5e-4, epoch = 60, CilpValue = 0.005\n"
      ],
      "metadata": {
        "id": "yUMj3RyKa90_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQvxqgDV-mNL",
        "outputId": "01c8858c-af2b-486c-e904-0a31b36d9477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 연결\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root = '/content/drive/MyDrive/Colab Notebooks/Gan기말과제/gan'\n",
        "\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn   # 신경망\n",
        "import torch.optim      # 최적화\n",
        "from torch.utils.data import dataloader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Seed\n",
        "\n",
        "seed = 100\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "# 하이퍼 파라미터\n",
        "\n",
        "Hyper_Parameters = {\n",
        "\n",
        "                     'num_workers' : 2,\n",
        "                     'batch_size' : 256,\n",
        "                     'image_size' : 64,\n",
        "                     'input_channels' : 3,     # CIFAR10 은 컬러영상 : RGB채널 필요\n",
        "                     'num_z' : 100,\n",
        "                     'hidden_gen' : 64,\n",
        "                     'hidden_disc' : 64,\n",
        "                     'num_epoch' : 60,\n",
        "                     'learning_rate' : 0.5e-4,\n",
        "                     'ClipValue' : 0.005\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "p_gGBsch-vqI"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Critic (Discriminator)\n",
        "- Sigmoid가 가 없는 형태"
      ],
      "metadata": {
        "id": "RXB90hDRTqVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module): # 비평자 : 점수를 매김 fake => - real => +\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.disc = nn.Sequential(\n",
        "\n",
        "                                    nn.Conv2d(\n",
        "                                                 Hyper_Parameters['input_channels'], Hyper_Parameters['hidden_gen'],\n",
        "                                                 kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                                 nn.LeakyReLU(0.2),\n",
        "                                                 nn.Conv2d(Hyper_Parameters['hidden_gen'], Hyper_Parameters['hidden_gen'] * 2,\n",
        "                                                 kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                                 nn.BatchNorm2d(Hyper_Parameters['hidden_gen'] * 2),\n",
        "                                                 nn.LeakyReLU(0.2),\n",
        "                                                 nn.Conv2d(Hyper_Parameters['hidden_gen'] * 2, Hyper_Parameters['hidden_gen'] * 4,\n",
        "                                                 kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                                 nn.BatchNorm2d(Hyper_Parameters['hidden_gen'] * 4),\n",
        "                                                 nn.LeakyReLU(0.2),\n",
        "                                                 nn.Conv2d(Hyper_Parameters['hidden_gen'] * 4, Hyper_Parameters['hidden_gen'] * 8,\n",
        "                                                 kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                                 nn.BatchNorm2d(Hyper_Parameters['hidden_gen'] * 8),\n",
        "                                                 nn.LeakyReLU(0.2),\n",
        "                                                 nn.Conv2d(Hyper_Parameters['hidden_gen'] * 8, 1,\n",
        "                                                 kernel_size=4, stride=1, padding=0, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.disc(input)"
      ],
      "metadata": {
        "id": "49VA-GdPRkY_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Generator\n",
        "\n",
        "- 수업시간에 작성한 Generator를 사용"
      ],
      "metadata": {
        "id": "hlcUVhQpYNoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "\n",
        "               nn.ConvTranspose2d(\n",
        "                                     Hyper_Parameters['num_z'], Hyper_Parameters['hidden_gen'] * 8,\n",
        "                                     kernel_size=4, stride=1, padding=0, bias=False),\n",
        "                                     nn.BatchNorm2d(Hyper_Parameters['hidden_gen'] * 8),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(Hyper_Parameters['hidden_gen'] * 8, Hyper_Parameters['hidden_gen'] * 4,\n",
        "                                     kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                     nn.BatchNorm2d(Hyper_Parameters['hidden_gen'] * 4),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(Hyper_Parameters['hidden_gen'] * 4, Hyper_Parameters['hidden_gen'] * 2,\n",
        "                                     kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                     nn.BatchNorm2d(Hyper_Parameters['hidden_gen'] * 2),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(Hyper_Parameters['hidden_gen'] * 2, Hyper_Parameters['hidden_gen'],\n",
        "                                     kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                     nn.BatchNorm2d(Hyper_Parameters['hidden_gen']),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(Hyper_Parameters['hidden_gen'], Hyper_Parameters['input_channels'],\n",
        "                                     kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                                     nn.Tanh()\n",
        "\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        return self.gen(input)"
      ],
      "metadata": {
        "id": "Lbty_7gmT43F"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 데이터셋 및 신경망 초기화(CIFAR 사용)\n",
        "- MNIST 사용 안함으로 삭제"
      ],
      "metadata": {
        "id": "j9pcvai2ZHWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.CIFAR10(\n",
        "\n",
        "        root=os.path.join(root, 'data'),\n",
        "        download=True,\n",
        "        transform=transforms.Compose([\n",
        "\n",
        "            transforms.Resize(Hyper_Parameters['image_size']),\n",
        "            transforms.CenterCrop(Hyper_Parameters['image_size']),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "\n",
        "        ))\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "\n",
        "     dataset, batch_size = Hyper_Parameters['batch_size'],\n",
        "     shuffle=True, num_workers = Hyper_Parameters['num_workers'])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLCTjWXlVXnz",
        "outputId": "9e7dfebc-a11b-4ca2-c409-b68d91aae747"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "\n",
        "    # 'ConvTranpose2d', 'Conv2d', 'ReLU', 'BatchNorm2d'\n",
        "\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "netG = Generator().to(device)\n",
        "netC = Critic().to(device)\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netC.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOuQnSOnaFQs",
        "outputId": "c8a8675f-ce42-4253-894d-dc6578acaa46"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Critic(\n",
              "  (disc): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Otimizer & 노이즈 생성\n",
        "\n",
        "- 기존의 Adam 대신 RMSprop을 사용한다."
      ],
      "metadata": {
        "id": "2gPoIrM3bc8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "optimizerG = torch.optim.RMSprop( netG.parameters(), lr = Hyper_Parameters['learning_rate'] )\n",
        "optimizerC = torch.optim.RMSprop( netC.parameters(), lr = Hyper_Parameters['learning_rate'] )\n",
        "\n",
        "fixed_noise = torch.randn(64, Hyper_Parameters['num_z'], 1, 1, device=device)\n",
        "print(fixed_noise.size())"
      ],
      "metadata": {
        "id": "d_nnjcOGa-lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cb18ae-5b76-4559-a4f6-818af6bdbe60"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 100, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. 학습 시작"
      ],
      "metadata": {
        "id": "DZNdgO4yfZro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---------------------------------------------------------------------------------------------\")\n",
        "print(\"학습 시작:\")\n",
        "print(\"---------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        # ============================================================= 시작\n",
        "\n",
        "iters = 0\n",
        "\n",
        "for epoch in range( Hyper_Parameters['num_epoch'] ):\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        # ============================================================= Critic_Real\n",
        "\n",
        "        netC.zero_grad()\n",
        "        real = data[0].to(device)\n",
        "        b_size = real.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float,device=device)\n",
        "\n",
        "        output = netC(real).view(-1)\n",
        "\n",
        "        outC_real =  output.mean().item() # Real\n",
        "        errC_real = -torch.mean(output) # WGAN 에서는 BSE대신 사용\n",
        "        errC_real.backward() # 학습\n",
        "\n",
        "        # outC_real => 양의 방향으로 가도록 학습\n",
        "\n",
        "        # ============================================================= Critic_Fake\n",
        "\n",
        "        noise = torch.randn(b_size, Hyper_Parameters['num_z'], 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "\n",
        "        output = netC(fake.detach()).view(-1)\n",
        "\n",
        "        outC_fake =  output.mean().item()\n",
        "\n",
        "        errC_fake = torch.mean(output) # 마찬가지로 BSE 대신 사용\n",
        "        errC_fake.backward() # 학습을 위해 역전파해줌\n",
        "\n",
        "        # =============================================================\n",
        "\n",
        "        # outC_fake => 음의 방향으로 가도록 학습\n",
        "\n",
        "        # outC_real - outC_fake가 증가하는 것은\n",
        "\n",
        "        # Critic의 구별 능력이 상승하고 있음을 나타낸다.\n",
        "\n",
        "        # ============================================================= Generator\n",
        "\n",
        "        optimizerC.step()\n",
        "\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "\n",
        "        output = netC(fake).view(-1)\n",
        "        errG = -torch.mean(output)\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        # ============================================================= WGAN Cliping 수행\n",
        "\n",
        "        for p in netC.parameters():\n",
        "          p.data.clamp_(-Hyper_Parameters['ClipValue'], Hyper_Parameters['ClipValue'])\n",
        "\n",
        "        # ============================================================= 현재 상태 출력\n",
        "\n",
        "        if iters % 100 == 0:\n",
        "\n",
        "            Progress = int((float(epoch) / float(Hyper_Parameters['num_epoch'])) * 10)\n",
        "            Bar = \"■\" * Progress + \"□\" * (10 - Progress)\n",
        "            print(Bar + \" | 현재 Epoch : %d | 총 Epoch : %d | 현재 iters : %d | \" % (epoch, Hyper_Parameters['num_epoch'], iters))\n",
        "\n",
        "        # ============================================================= 영상 1000 iter마다 저장\n",
        "\n",
        "        if (iters % 1000 == 0): # 1000 iter 마다의 결과를 저장\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "\n",
        "            plt.figure(figsize=(8, 8))  # 8x8\n",
        "            plt.axis(\"off\")\n",
        "            plt.imshow(\n",
        "                np.transpose(\n",
        "                    vutils.make_grid(fake.to(device)[:64],\n",
        "                                    padding=2, normalize=True).cpu(),\n",
        "                                     (1, 2, 0)))\n",
        "\n",
        "            frame_path = os.path.join(root, \"Image{}.png\".format(iters))\n",
        "            plt.savefig(frame_path, bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "Xd7hmudifY_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c4b659-222d-49c2-b004-b489d7d24acb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------\n",
            "학습 시작:\n",
            "---------------------------------------------------------------------------------------------\n",
            "□□□□□□□□□□ | 현재 Epoch : 0 | 총 Epoch : 60 | 현재 iters : 0 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 0 | 총 Epoch : 60 | 현재 iters : 100 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 1 | 총 Epoch : 60 | 현재 iters : 200 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 1 | 총 Epoch : 60 | 현재 iters : 300 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 2 | 총 Epoch : 60 | 현재 iters : 400 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 2 | 총 Epoch : 60 | 현재 iters : 500 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 3 | 총 Epoch : 60 | 현재 iters : 600 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 3 | 총 Epoch : 60 | 현재 iters : 700 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 4 | 총 Epoch : 60 | 현재 iters : 800 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 4 | 총 Epoch : 60 | 현재 iters : 900 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 5 | 총 Epoch : 60 | 현재 iters : 1000 | \n",
            "□□□□□□□□□□ | 현재 Epoch : 5 | 총 Epoch : 60 | 현재 iters : 1100 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 6 | 총 Epoch : 60 | 현재 iters : 1200 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 6 | 총 Epoch : 60 | 현재 iters : 1300 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 7 | 총 Epoch : 60 | 현재 iters : 1400 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 7 | 총 Epoch : 60 | 현재 iters : 1500 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 8 | 총 Epoch : 60 | 현재 iters : 1600 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 8 | 총 Epoch : 60 | 현재 iters : 1700 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 9 | 총 Epoch : 60 | 현재 iters : 1800 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 9 | 총 Epoch : 60 | 현재 iters : 1900 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 10 | 총 Epoch : 60 | 현재 iters : 2000 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 10 | 총 Epoch : 60 | 현재 iters : 2100 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 11 | 총 Epoch : 60 | 현재 iters : 2200 | \n",
            "■□□□□□□□□□ | 현재 Epoch : 11 | 총 Epoch : 60 | 현재 iters : 2300 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 12 | 총 Epoch : 60 | 현재 iters : 2400 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 12 | 총 Epoch : 60 | 현재 iters : 2500 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 13 | 총 Epoch : 60 | 현재 iters : 2600 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 13 | 총 Epoch : 60 | 현재 iters : 2700 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 14 | 총 Epoch : 60 | 현재 iters : 2800 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 14 | 총 Epoch : 60 | 현재 iters : 2900 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 15 | 총 Epoch : 60 | 현재 iters : 3000 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 15 | 총 Epoch : 60 | 현재 iters : 3100 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 16 | 총 Epoch : 60 | 현재 iters : 3200 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 16 | 총 Epoch : 60 | 현재 iters : 3300 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 17 | 총 Epoch : 60 | 현재 iters : 3400 | \n",
            "■■□□□□□□□□ | 현재 Epoch : 17 | 총 Epoch : 60 | 현재 iters : 3500 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 18 | 총 Epoch : 60 | 현재 iters : 3600 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 18 | 총 Epoch : 60 | 현재 iters : 3700 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 19 | 총 Epoch : 60 | 현재 iters : 3800 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 19 | 총 Epoch : 60 | 현재 iters : 3900 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 20 | 총 Epoch : 60 | 현재 iters : 4000 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 20 | 총 Epoch : 60 | 현재 iters : 4100 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 21 | 총 Epoch : 60 | 현재 iters : 4200 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 21 | 총 Epoch : 60 | 현재 iters : 4300 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 22 | 총 Epoch : 60 | 현재 iters : 4400 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 22 | 총 Epoch : 60 | 현재 iters : 4500 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 23 | 총 Epoch : 60 | 현재 iters : 4600 | \n",
            "■■■□□□□□□□ | 현재 Epoch : 23 | 총 Epoch : 60 | 현재 iters : 4700 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 24 | 총 Epoch : 60 | 현재 iters : 4800 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 25 | 총 Epoch : 60 | 현재 iters : 4900 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 25 | 총 Epoch : 60 | 현재 iters : 5000 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 26 | 총 Epoch : 60 | 현재 iters : 5100 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 26 | 총 Epoch : 60 | 현재 iters : 5200 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 27 | 총 Epoch : 60 | 현재 iters : 5300 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 27 | 총 Epoch : 60 | 현재 iters : 5400 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 28 | 총 Epoch : 60 | 현재 iters : 5500 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 28 | 총 Epoch : 60 | 현재 iters : 5600 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 29 | 총 Epoch : 60 | 현재 iters : 5700 | \n",
            "■■■■□□□□□□ | 현재 Epoch : 29 | 총 Epoch : 60 | 현재 iters : 5800 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 30 | 총 Epoch : 60 | 현재 iters : 5900 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 30 | 총 Epoch : 60 | 현재 iters : 6000 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 31 | 총 Epoch : 60 | 현재 iters : 6100 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 31 | 총 Epoch : 60 | 현재 iters : 6200 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 32 | 총 Epoch : 60 | 현재 iters : 6300 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 32 | 총 Epoch : 60 | 현재 iters : 6400 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 33 | 총 Epoch : 60 | 현재 iters : 6500 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 33 | 총 Epoch : 60 | 현재 iters : 6600 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 34 | 총 Epoch : 60 | 현재 iters : 6700 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 34 | 총 Epoch : 60 | 현재 iters : 6800 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 35 | 총 Epoch : 60 | 현재 iters : 6900 | \n",
            "■■■■■□□□□□ | 현재 Epoch : 35 | 총 Epoch : 60 | 현재 iters : 7000 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 36 | 총 Epoch : 60 | 현재 iters : 7100 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 36 | 총 Epoch : 60 | 현재 iters : 7200 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 37 | 총 Epoch : 60 | 현재 iters : 7300 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 37 | 총 Epoch : 60 | 현재 iters : 7400 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 38 | 총 Epoch : 60 | 현재 iters : 7500 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 38 | 총 Epoch : 60 | 현재 iters : 7600 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 39 | 총 Epoch : 60 | 현재 iters : 7700 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 39 | 총 Epoch : 60 | 현재 iters : 7800 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 40 | 총 Epoch : 60 | 현재 iters : 7900 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 40 | 총 Epoch : 60 | 현재 iters : 8000 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 41 | 총 Epoch : 60 | 현재 iters : 8100 | \n",
            "■■■■■■□□□□ | 현재 Epoch : 41 | 총 Epoch : 60 | 현재 iters : 8200 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 42 | 총 Epoch : 60 | 현재 iters : 8300 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 42 | 총 Epoch : 60 | 현재 iters : 8400 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 43 | 총 Epoch : 60 | 현재 iters : 8500 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 43 | 총 Epoch : 60 | 현재 iters : 8600 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 44 | 총 Epoch : 60 | 현재 iters : 8700 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 44 | 총 Epoch : 60 | 현재 iters : 8800 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 45 | 총 Epoch : 60 | 현재 iters : 8900 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 45 | 총 Epoch : 60 | 현재 iters : 9000 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 46 | 총 Epoch : 60 | 현재 iters : 9100 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 46 | 총 Epoch : 60 | 현재 iters : 9200 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 47 | 총 Epoch : 60 | 현재 iters : 9300 | \n",
            "■■■■■■■□□□ | 현재 Epoch : 47 | 총 Epoch : 60 | 현재 iters : 9400 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 48 | 총 Epoch : 60 | 현재 iters : 9500 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 48 | 총 Epoch : 60 | 현재 iters : 9600 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 49 | 총 Epoch : 60 | 현재 iters : 9700 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 50 | 총 Epoch : 60 | 현재 iters : 9800 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 50 | 총 Epoch : 60 | 현재 iters : 9900 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 51 | 총 Epoch : 60 | 현재 iters : 10000 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 51 | 총 Epoch : 60 | 현재 iters : 10100 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 52 | 총 Epoch : 60 | 현재 iters : 10200 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 52 | 총 Epoch : 60 | 현재 iters : 10300 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 53 | 총 Epoch : 60 | 현재 iters : 10400 | \n",
            "■■■■■■■■□□ | 현재 Epoch : 53 | 총 Epoch : 60 | 현재 iters : 10500 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 54 | 총 Epoch : 60 | 현재 iters : 10600 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 54 | 총 Epoch : 60 | 현재 iters : 10700 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 55 | 총 Epoch : 60 | 현재 iters : 10800 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 55 | 총 Epoch : 60 | 현재 iters : 10900 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 56 | 총 Epoch : 60 | 현재 iters : 11000 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 56 | 총 Epoch : 60 | 현재 iters : 11100 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 57 | 총 Epoch : 60 | 현재 iters : 11200 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 57 | 총 Epoch : 60 | 현재 iters : 11300 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 58 | 총 Epoch : 60 | 현재 iters : 11400 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 58 | 총 Epoch : 60 | 현재 iters : 11500 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 59 | 총 Epoch : 60 | 현재 iters : 11600 | \n",
            "■■■■■■■■■□ | 현재 Epoch : 59 | 총 Epoch : 60 | 현재 iters : 11700 | \n"
          ]
        }
      ]
    }
  ]
}